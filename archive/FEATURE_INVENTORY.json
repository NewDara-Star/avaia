{
  "metadata": {
    "product_name": "Avaia",
    "product_type": "AI-Powered Programming Education Platform",
    "analysis_date": "2026-01-23",
    "version_analyzed": "1.7.0",
    "architecture": "Hybrid (TypeScript MCP Server + Python/Flask Desktop GUI)",
    "deployment": "Native macOS Application + CLI Tool"
  },

  "core_entities": [
    {
      "entity": "Learner",
      "description": "A student using Avaia to learn programming",
      "attributes": [
        "id (unique identifier)",
        "name",
        "started_at (timestamp)",
        "preferred_teaching_method (example_first | concept_first | try_first)",
        "best_session_times (JSON array)",
        "onboarding_complete (boolean)",
        "learning_preferences (JSON object with flags like prefers_physical_analogies)",
        "current_track_id (foreign key to learning track)"
      ],
      "business_rules": [
        "Learner ID must be unique and persist across sessions",
        "Learner must complete onboarding before starting first project",
        "Learning preferences are auto-detected and updated during sessions based on AI observations",
        "Learner can only have one active project at a time"
      ]
    },
    {
      "entity": "Project",
      "description": "A coding project that learners build to practice concepts",
      "attributes": [
        "id",
        "learner_id",
        "name",
        "status (not_started | in_progress | completed)",
        "current_milestone (integer)",
        "milestones_completed (JSON array)",
        "time_spent_minutes",
        "started_at",
        "completed_at",
        "template_id (optional, links to curriculum template)"
      ],
      "business_rules": [
        "Projects must advance milestone-by-milestone (cannot skip)",
        "Only one project can be 'in_progress' per learner at a time",
        "Milestones must be verified before advancing",
        "Time spent is tracked automatically during sessions"
      ]
    },
    {
      "entity": "Concept",
      "description": "A programming concept or skill (e.g., 'forEach', 'async/await', 'closures')",
      "attributes": [
        "id",
        "name",
        "category",
        "cluster (for interleaving similar concepts)",
        "prerequisites (JSON array of concept IDs)",
        "sandbox_id (optional productive failure exercise)",
        "visualizations (JSON array of URLs)"
      ],
      "business_rules": [
        "Concepts have prerequisites that must be introduced first",
        "Concepts are introduced just-in-time when the project requires them",
        "Each concept can have multiple diagnostic questions",
        "Concepts use FSRS-5 for spaced repetition scheduling"
      ]
    },
    {
      "entity": "Learner_Concept",
      "description": "Per-learner state of a concept (mastery, FSRS state, stubborn bugs)",
      "attributes": [
        "learner_id",
        "concept_id",
        "stability (FSRS-5 parameter)",
        "difficulty (FSRS-5 parameter)",
        "state (new | learning | review | relearning)",
        "reps (repetition count)",
        "lapses (failure count)",
        "last_review_date",
        "next_review_date",
        "introduced_at",
        "verified (boolean)",
        "verified_at",
        "independence_score (0-100, affects hint level)",
        "confidence_history (JSON array)",
        "stubborn_misconceptions (JSON array of misconception IDs)",
        "total_attempts",
        "correct_attempts"
      ],
      "business_rules": [
        "FSRS-5 algorithm determines next_review_date based on performance",
        "Stubborn bugs are flagged when high confidence + wrong answer",
        "Independence score increases with correct attempts without hints",
        "Concepts in 'relearning' state have highest priority for review",
        "Next review date uses spaced repetition intervals (days: 1, 3, 7, 14, 30, etc.)"
      ]
    },
    {
      "entity": "Session",
      "description": "A single learning session with the AI tutor",
      "attributes": [
        "id",
        "learner_id",
        "project_id (optional)",
        "start_time",
        "end_time",
        "planned_duration_minutes",
        "actual_duration_minutes",
        "milestones_attempted (JSON array)",
        "milestones_completed (JSON array)",
        "concepts_introduced (JSON array)",
        "concepts_verified (JSON array)",
        "srs_reviews_given",
        "srs_reviews_passed",
        "emotional_states (JSON array)",
        "learner_questions (JSON array)",
        "exit_ticket_concept",
        "exit_ticket_passed (boolean)",
        "session_notes (natural language summary for continuity)"
      ],
      "business_rules": [
        "Sessions follow 7-phase structure: Check-in, Goal, Sandbox, Build, Concept, Verification, Reflection",
        "Session notes are mandatory for end_session tool call",
        "Exit ticket is required if new concepts were introduced",
        "Emotional states are inferred from message timing patterns",
        "Sessions without learner questions trigger passive learner detection"
      ]
    },
    {
      "entity": "Diagnostic_Question",
      "description": "Multiple-choice question to verify concept understanding",
      "attributes": [
        "id",
        "concept_id",
        "code_snippet (optional)",
        "prompt",
        "correct_answer",
        "distractors (JSON array of {answer, misconception_id})"
      ],
      "business_rules": [
        "Distractors are mapped to specific misconceptions",
        "Used for verification phase after teaching",
        "Used for exit tickets at session end",
        "Questions use learner's own code when available"
      ]
    },
    {
      "entity": "Misconception",
      "description": "A common incorrect mental model learners develop",
      "attributes": [
        "id",
        "concept_id",
        "name",
        "description",
        "trigger_answer (which wrong answer reveals this)",
        "remediation_strategy",
        "contrasting_case (JSON with two code snippets showing the difference)"
      ],
      "business_rules": [
        "Stubborn misconceptions are tracked per learner (high confidence + wrong)",
        "Remediation takes priority over new content",
        "Contrasting cases must show minimal difference between correct and incorrect"
      ]
    },
    {
      "entity": "Sandbox",
      "description": "Productive failure exercise - deliberately challenging problem presented before teaching",
      "attributes": [
        "id",
        "concept_id",
        "problem_statement",
        "setup_code (optional)",
        "expected_failures (JSON array of failure patterns)",
        "min_attempts (default 2)",
        "reflection_questions (JSON array)",
        "teaching_transition (text to bridge from failure to concept)"
      ],
      "business_rules": [
        "Sandbox must be attempted BEFORE teaching the concept",
        "Learner must make at least min_attempts tries",
        "AI must NOT help learner succeed - failure is the goal",
        "After sandbox, AI explains why failure occurred, then teaches concept"
      ]
    },
    {
      "entity": "Learning_Track",
      "description": "A structured curriculum path (e.g., JavaScript/Web, Python/Data, CS Theory)",
      "attributes": [
        "id",
        "name",
        "description",
        "estimated_hours",
        "difficulty_level",
        "prerequisites (JSON array)"
      ],
      "business_rules": [
        "Tracks contain multiple project templates in sequence",
        "Learner selects track during onboarding",
        "Track progress is calculated as (completed projects / total projects)",
        "Custom tracks can be dynamically generated for non-standard topics"
      ]
    },
    {
      "entity": "Project_Template",
      "description": "A pre-designed project within a learning track",
      "attributes": [
        "id",
        "track_id",
        "sequence_order (integer)",
        "name",
        "description",
        "estimated_hours",
        "milestones (JSON array)",
        "concepts_taught (JSON array of concept IDs)"
      ],
      "business_rules": [
        "Templates are instantiated as Projects when learner starts them",
        "Sequence order determines project progression",
        "Must specify all concepts taught for curriculum coherence"
      ]
    }
  ],

  "user_stories": [
    {
      "id": "US001",
      "category": "Onboarding",
      "story": "As a new learner, I can create a profile so that my progress is tracked",
      "acceptance_criteria": [
        "System generates unique learner ID",
        "Learner can set optional name",
        "Learner selects preferred teaching method",
        "Learner can specify best session times",
        "Profile persists in SQLite database"
      ],
      "implementation": "create_learner MCP tool, POST /api/learner/create endpoint"
    },
    {
      "id": "US002",
      "category": "Onboarding",
      "story": "As a new learner, I can select a learning track so that I follow a structured curriculum",
      "acceptance_criteria": [
        "System displays available tracks (js-web, python-data, cs-theory, etc.)",
        "Learner can preview track description and project list",
        "Selecting track marks onboarding complete",
        "First project from track is automatically started"
      ],
      "implementation": "complete_onboarding MCP tool, POST /api/select-track endpoint"
    },
    {
      "id": "US003",
      "category": "Session Management",
      "story": "As a learner, I can start a learning session so that the AI has context about my current state",
      "acceptance_criteria": [
        "Session retrieves previous session notes",
        "Session loads current project state",
        "Session identifies due reviews (FSRS)",
        "Session identifies stubborn bugs",
        "Session loads known vocabulary terms",
        "Session loads learning preferences",
        "Returns all data in one consolidated call"
      ],
      "implementation": "start_session MCP tool (consolidated check-in data)"
    },
    {
      "id": "US004",
      "category": "Session Management",
      "story": "As a learner, I can end a session so that my progress and context are saved for next time",
      "acceptance_criteria": [
        "Session notes must be provided (natural language summary)",
        "Session duration is calculated automatically",
        "Session captures concepts introduced and verified",
        "Session captures emotional journey",
        "Exit ticket pass/fail is recorded",
        "Session notes answer: what was worked on, blockers, learner state, next steps"
      ],
      "implementation": "end_session MCP tool"
    },
    {
      "id": "US005",
      "category": "Project Building",
      "story": "As a learner, I can work on a project milestone so that I apply concepts in practice",
      "acceptance_criteria": [
        "System shows current milestone requirements",
        "AI introduces concepts just-in-time when needed",
        "AI provides scaffolded hints based on independence score",
        "AI does not give direct answers without verification",
        "Milestone cannot be advanced without verification"
      ],
      "implementation": "get_project_state, get_next_step, introduce_concept MCP tools"
    },
    {
      "id": "US006",
      "category": "Project Building",
      "story": "As a learner, I can complete a milestone so that I progress through the project",
      "acceptance_criteria": [
        "Milestone must be verified before completion",
        "System updates milestones_completed array",
        "System advances current_milestone counter",
        "System updates time_spent_minutes",
        "Next milestone requirements are shown"
      ],
      "implementation": "advance_milestone MCP tool"
    },
    {
      "id": "US007",
      "category": "Concept Learning",
      "story": "As a learner, I encounter productive failure exercises before learning complex concepts so that I create mental 'slots' for new knowledge",
      "acceptance_criteria": [
        "Sandbox is triggered before teaching concept",
        "AI presents ill-structured problem",
        "AI instructs learner to try 2-3 approaches",
        "AI does NOT help learner succeed",
        "AI evaluates attempts against expected failure patterns",
        "AI asks reflection questions after failure",
        "AI teaches concept using failure as context"
      ],
      "implementation": "trigger_sandbox, evaluate_sandbox_attempt MCP tools"
    },
    {
      "id": "US008",
      "category": "Concept Learning",
      "story": "As a learner, I am taught concepts using my own project code so that learning is contextual",
      "acceptance_criteria": [
        "AI explains concept using code snippet from learner's project",
        "Code snippet is stored for future reviews (~500 chars)",
        "Explanation addresses 5 questions: Why, How, When, Where, What",
        "Concept is marked as introduced with timestamp",
        "Snippet includes context (e.g., 'Task Tracker, handleSubmit function')"
      ],
      "implementation": "introduce_concept, store_code_snippet MCP tools"
    },
    {
      "id": "US009",
      "category": "Verification",
      "story": "As a learner, I am verified after claiming understanding so that misconceptions are caught early",
      "acceptance_criteria": [
        "AI NEVER accepts 'I get it' without verification",
        "AI asks diagnostic question immediately after teaching",
        "Question uses learner's actual code when possible",
        "Question has 4 options: 1 correct, 3 distractors (mapped to misconceptions)",
        "If wrong: AI identifies misconception and clarifies",
        "If high confidence + wrong: AI flags as stubborn bug",
        "AI asks follow-up verification question before continuing"
      ],
      "implementation": "get_diagnostic_question, verify_concept MCP tools"
    },
    {
      "id": "US010",
      "category": "Verification",
      "story": "As a learner with stubborn misconceptions, I receive contrasting cases so that I can discriminate correct from incorrect patterns",
      "acceptance_criteria": [
        "System detects stubborn bug (high confidence + wrong answer repeated)",
        "AI retrieves contrasting case (two code snippets)",
        "AI shows side-by-side comparison",
        "AI asks: 'What's the ONE difference that changes the outcome?'",
        "Learner must re-verify before continuing",
        "Stubborn misconception is tracked in learner_concept.stubborn_misconceptions"
      ],
      "implementation": "flag_stubborn_bug, get_contrasting_case MCP tools"
    },
    {
      "id": "US011",
      "category": "Spaced Repetition",
      "story": "As a learner, I review concepts at optimal intervals so that I retain knowledge long-term",
      "acceptance_criteria": [
        "System uses FSRS-5 algorithm for scheduling",
        "Reviews use code snippets from learner's own projects",
        "Reviews are prioritized: relearning > learning > review > new",
        "Review outcome (correct/incorrect) updates FSRS state",
        "Confidence rating (1-5) affects next interval",
        "Response time affects rating conversion",
        "Next review date calculated based on stability"
      ],
      "implementation": "get_due_reviews, log_review MCP tools, FSRS-5 library"
    },
    {
      "id": "US012",
      "category": "Spaced Repetition",
      "story": "As a learner, I receive refactoring challenges when concepts decay so that I reapply knowledge across projects",
      "acceptance_criteria": [
        "System detects significantly decayed concept (low stability)",
        "AI retrieves code snippet from different project",
        "AI asks: 'How would you apply this pattern in your current project?'",
        "Challenge is small (5-10 minute task)",
        "If no cross-project code exists, AI generates focused exercise",
        "Completing challenge updates FSRS state"
      ],
      "implementation": "get_refactoring_challenge MCP tool"
    },
    {
      "id": "US013",
      "category": "Emotional Intelligence",
      "story": "As a learner, my emotional state is inferred from message timing so that the AI can intervene appropriately",
      "acceptance_criteria": [
        "System logs gap between messages (milliseconds)",
        "Long gaps (>5 min) suggest disengagement",
        "Rapid short messages suggest frustration",
        "Zero learner questions suggest passivity",
        "Help request patterns are tracked",
        "Inferred state: flow | struggling | frustrated | disengaged | passive",
        "Intervention script is retrieved for detected state"
      ],
      "implementation": "log_message_timing, infer_emotional_state, get_intervention MCP tools"
    },
    {
      "id": "US014",
      "category": "Emotional Intelligence",
      "story": "As a frustrated learner, I receive appropriate intervention so that I don't give up",
      "acceptance_criteria": [
        "AI detects frustration from timing or language patterns",
        "AI acknowledges emotion: 'This seems frustrating'",
        "AI offers break or different approach",
        "AI reduces difficulty or increases scaffolding",
        "AI checks prerequisites if repeated failure",
        "Intervention is logged in session.emotional_states"
      ],
      "implementation": "Emotion detection rules in system prompt + intervention scripts"
    },
    {
      "id": "US015",
      "category": "Adaptive Teaching",
      "story": "As a learner, I receive hints at my independence level so that I'm challenged but not overwhelmed",
      "acceptance_criteria": [
        "Independence score ranges 0-100",
        "Score increases with correct attempts without hints",
        "Score decreases with hint requests or failures",
        "Hint levels: 0-25 (Full), 26-50 (Detailed), 51-75 (Conceptual), 76-90 (Nudge), 91-100 (Socratic)",
        "AI retrieves hint via get_hint(concept_id, learner_id)",
        "Hint respects current independence level"
      ],
      "implementation": "get_hint MCP tool, independence_score in learner_concept"
    },
    {
      "id": "US016",
      "category": "Adaptive Teaching",
      "story": "As a learner, my learning preferences are auto-detected so that teaching adapts to my style",
      "acceptance_criteria": [
        "Preferences detected: prefers_physical_analogies, prefers_direct_feedback, struggles_with_abstract_execution, needs_emotional_context, tangent_prone, prefers_visual_diagrams",
        "Physical analogies preference: detected when physical metaphor works after abstract fails",
        "Direct feedback preference: detected when learner says 'don't be nice about it'",
        "Async struggle: detected after repeated confusion with timing concepts",
        "AI calls update_learning_preferences when pattern observed",
        "Preferences returned by start_session for immediate adaptation"
      ],
      "implementation": "update_learning_preferences MCP tool, learning_preferences field in learner"
    },
    {
      "id": "US017",
      "category": "Anti-Sycophancy",
      "story": "As a learner, I am challenged when I make incorrect assumptions so that I build accurate mental models",
      "acceptance_criteria": [
        "AI NEVER starts with 'Great question!' or 'You're right!'",
        "AI challenges incorrect assumptions immediately",
        "AI asks clarifying questions before answering",
        "AI requires explanation before providing implementation",
        "AI points out misconceptions kindly but directly",
        "AI uses phrases: 'Walk me through...', 'Explain why...'",
        "AI does NOT provide code before understanding is verified"
      ],
      "implementation": "System prompt rules, verified via verification phase"
    },
    {
      "id": "US018",
      "category": "Session Continuity",
      "story": "As a returning learner, I can resume where I left off so that sessions feel connected",
      "acceptance_criteria": [
        "start_session retrieves previous session notes",
        "AI greets learner with context: 'Last time you were working on X'",
        "AI mentions blockers from previous session",
        "AI recalls learner's emotional state at end of last session",
        "AI suggests next steps based on previous session notes"
      ],
      "implementation": "Session notes in end_session, retrieved by start_session"
    },
    {
      "id": "US019",
      "category": "Dashboard",
      "story": "As a learner, I can view my learning metrics so that I see my progress",
      "acceptance_criteria": [
        "Dashboard shows: total sessions, total time, current streak (days)",
        "Dashboard shows: concepts introduced, learning, mastered",
        "Dashboard shows: due reviews count",
        "Dashboard shows: stubborn bugs count",
        "Dashboard shows: current project progress (milestones)",
        "Dashboard shows: track progress (projects completed/total)",
        "Dashboard shows: independence score, verification pass rate"
      ],
      "implementation": "GET /api/dashboard endpoint, dashboard.html template"
    },
    {
      "id": "US020",
      "category": "Dashboard",
      "story": "As a learner, I can view my concept mastery so that I know what I've learned",
      "acceptance_criteria": [
        "Shows concepts by state: mastered, learning, new",
        "Shows mastered concepts with verified_at timestamp",
        "Shows learning concepts with next_review_date",
        "Shows known vocabulary terms",
        "Shows stubborn misconceptions flagged",
        "Can filter by category"
      ],
      "implementation": "GET /api/learning endpoint, learning.html template"
    },
    {
      "id": "US021",
      "category": "Reviews",
      "story": "As a learner, I can see my due reviews so that I practice spaced repetition",
      "acceptance_criteria": [
        "Shows count of due reviews",
        "Shows code snippets for each review",
        "Shows snippet context (e.g., 'From Task Tracker project')",
        "Shows diagnostic question with 4 options",
        "Allows confidence rating (1-5)",
        "Tracks response time",
        "Updates FSRS state after submission"
      ],
      "implementation": "GET /api/reviews endpoint, POST /api/log-review, reviews.html template"
    },
    {
      "id": "US022",
      "category": "Projects",
      "story": "As a learner, I can view my project progress so that I see what I've built",
      "acceptance_criteria": [
        "Shows all projects: not_started, in_progress, completed",
        "Shows milestones completed per project",
        "Shows time spent per project",
        "Shows current milestone for active project",
        "Shows track progress bar",
        "Can click to resume active project"
      ],
      "implementation": "GET /api/projects endpoint, projects.html template"
    },
    {
      "id": "US023",
      "category": "Setup",
      "story": "As a new user, I can install dependencies via setup wizard so that the app works",
      "acceptance_criteria": [
        "Preflight checks: Claude CLI installed, MCP configured, database initialized, API key set",
        "Can install Claude CLI via npm",
        "Can configure Avaia MCP server in Claude config",
        "Can initialize SQLite database with migrations",
        "Can login to Claude.ai OR set API key (BYOK)",
        "Invalidates preflight cache when API key is set",
        "Setup wizard blocks main app until complete"
      ],
      "implementation": "GET /setup, POST /setup/install/<component>, setup_wizard.py"
    },
    {
      "id": "US024",
      "category": "Voice Input",
      "story": "As a learner, I can use voice input so that I can speak instead of type",
      "acceptance_criteria": [
        "Uses Whisper WASM (offline via Transformers.js)",
        "No internet required for speech recognition",
        "Voice button toggles recording",
        "Transcription appears in message input",
        "Works in macOS native app"
      ],
      "implementation": "Frontend JavaScript using Transformers.js pipeline"
    },
    {
      "id": "US025",
      "category": "Text-to-Speech",
      "story": "As a learner, I can hear AI responses so that I can learn while doing other things",
      "acceptance_criteria": [
        "Uses Web Speech API",
        "Smart voice selection (prefers enhanced quality)",
        "Speak button on each message",
        "Can stop mid-speech",
        "Works with markdown-rendered content (strips formatting)"
      ],
      "implementation": "Frontend JavaScript using Web Speech API"
    },
    {
      "id": "US026",
      "category": "Chat Interface",
      "story": "As a learner, I can have a conversation with the AI so that I get personalized teaching",
      "acceptance_criteria": [
        "Real-time streaming responses via WebSocket (Socket.IO)",
        "Markdown rendering with code highlighting",
        "Message history persists in localStorage",
        "Can restart conversation (new session)",
        "Can stop AI mid-response",
        "Model selection: Sonnet (default), Opus, Haiku",
        "Learner ID persists across sessions"
      ],
      "implementation": "index.html template, Socket.IO events, Flask-SocketIO backend"
    },
    {
      "id": "US027",
      "category": "Curriculum Management",
      "story": "As an educator, I can seed curriculum data so that learners have structured tracks",
      "acceptance_criteria": [
        "Seed scripts populate: learning_track, project_template, concept, diagnostic_question, misconception, sandbox",
        "Tracks available: js-web, python-data, dsa, cs-theory, ml-engineering, software-engineering, c-systems, avaia-core",
        "Each track has sequence of projects with milestones",
        "Each project specifies concepts_taught",
        "Seed scripts are idempotent (can run multiple times)"
      ],
      "implementation": "TypeScript seed scripts in /scripts, run via npm run seed"
    },
    {
      "id": "US028",
      "category": "Dynamic Curriculum",
      "story": "As a learner, I can request a custom learning path so that I learn non-standard topics",
      "acceptance_criteria": [
        "AI detects 'I want to learn [topic]' pattern",
        "AI checks if pre-seeded track exists",
        "If not exists: AI asks clarifying questions (experience, context, time)",
        "AI suggests switching to Opus for curriculum planning",
        "AI calls generate_learning_track(learner_id, goal, context)",
        "Track is saved to database automatically",
        "AI presents track overview for confirmation",
        "First project starts upon confirmation"
      ],
      "implementation": "System prompt rules, generate_learning_track MCP tool (inferred from prompt)"
    },
    {
      "id": "US029",
      "category": "Curriculum Updates",
      "story": "As a user, I can update curriculum so that I get new content",
      "acceptance_criteria": [
        "System checks for npm package updates (@newdara/avaia)",
        "System checks for pending SQL migrations",
        "User can trigger update via API",
        "Update applies migrations in order",
        "Update marks migrations as applied in _migrations table"
      ],
      "implementation": "GET /api/curriculum/status, POST /api/curriculum/update"
    },
    {
      "id": "US030",
      "category": "Exit Ticket",
      "story": "As a learner, I answer an exit ticket so that my understanding is verified before leaving",
      "acceptance_criteria": [
        "Exit ticket is required if concepts were introduced this session",
        "Exit ticket asks about random concept from today's session",
        "Uses diagnostic question format (multiple choice)",
        "If learner fails: quick remediation, then repeat",
        "Pass/fail is recorded in session.exit_ticket_passed",
        "If no new concepts: exit ticket is optional"
      ],
      "implementation": "get_exit_ticket MCP tool, triggered by end_session"
    },
    {
      "id": "US031",
      "category": "Question Tracking",
      "story": "As a learner, my questions are tracked so that passivity is detected",
      "acceptance_criteria": [
        "System logs each learner question with type (how, why, what, other)",
        "System tracks sessions_without_questions counter",
        "If 2+ sessions without questions: AI prompts for questions",
        "Why-questions are flagged as deeper engagement",
        "Prompted vs unprompted questions are distinguished",
        "Question patterns analyzed: avg per session, type distribution"
      ],
      "implementation": "log_learner_question, should_prompt_questions, get_question_patterns MCP tools"
    },
    {
      "id": "US032",
      "category": "Chat History",
      "story": "As a system, I log complete conversation history so that debugging and analysis are possible",
      "acceptance_criteria": [
        "Every message logged: user, assistant, system",
        "Tool calls and results captured for assistant messages",
        "Tokens used tracked per message (optional)",
        "Timestamp recorded for each message",
        "Can retrieve history by session, role, or time range",
        "Logging happens at GUI level (zero AI overhead)"
      ],
      "implementation": "log_chat_message, get_chat_history MCP tools, auto_log_message in server_webview.py"
    },
    {
      "id": "US033",
      "category": "Passive Learner Detection",
      "story": "As a learner who rarely asks questions, I am prompted so that I engage more actively",
      "acceptance_criteria": [
        "System detects 0 learner questions in session",
        "After ~30 minutes: AI calls should_prompt_questions",
        "If 2+ sessions without questions: AI prompts",
        "AI says: 'What questions do you have about this? Even partial ones are valuable.'",
        "Passive state logged in emotional_states"
      ],
      "implementation": "should_prompt_questions MCP tool, passive detection in system prompt"
    },
    {
      "id": "US034",
      "category": "Tangent Handling",
      "story": "As a tangent-prone learner, I am redirected to verify understanding before exploring",
      "acceptance_criteria": [
        "AI detects 3+ conceptual questions without code/verification",
        "AI says: 'I love this curiosity. Let's verify understanding first.'",
        "AI asks ONE verification question about what was taught",
        "THEN AI allows tangent exploration",
        "Tangent-prone preference is flagged and tracked"
      ],
      "implementation": "System prompt rules, tangent_prone flag in learning_preferences"
    },
    {
      "id": "US035",
      "category": "Session Summary",
      "story": "As a learner, I can view session summary so that I see what was accomplished",
      "acceptance_criteria": [
        "Summary shows: duration, concepts introduced, concepts verified",
        "Summary shows: milestones completed, reviews passed",
        "Summary shows: emotional journey (states logged during session)",
        "Summary shows: questions asked count",
        "Summary shows: exit ticket result",
        "Summary shows: session notes"
      ],
      "implementation": "get_session_summary MCP tool"
    }
  ],

  "business_rules": [
    {
      "rule_id": "BR001",
      "category": "Session Lifecycle",
      "rule": "Sessions must start with start_session and end with end_session",
      "rationale": "Ensures proper context loading and state persistence"
    },
    {
      "rule_id": "BR002",
      "category": "Concept Introduction",
      "rule": "introduce_concept must be called whenever AI teaches any programming method, pattern, or feature",
      "rationale": "Without this, system cannot track what learner knows or schedule reviews",
      "enforcement": "System prompt marks this as MANDATORY with red flags"
    },
    {
      "rule_id": "BR003",
      "category": "Verification",
      "rule": "After teaching a concept, verification is MANDATORY before proceeding to next milestone",
      "rationale": "Prevents learners from building on flawed understanding",
      "enforcement": "System prompt forbids skipping verification"
    },
    {
      "rule_id": "BR004",
      "category": "Stubborn Bugs",
      "rule": "If confidence ≥ 4 AND answer is wrong: flag as stubborn bug, require remediation",
      "rationale": "High confidence + wrong indicates deeply embedded misconception",
      "enforcement": "verify_concept tool checks confidence + correctness, updates stubborn_misconceptions"
    },
    {
      "rule_id": "BR005",
      "category": "Hint Scaffolding",
      "rule": "Hint level must respect independence_score: lower score = more detailed hints",
      "rationale": "Prevents overwhelming beginners or boring advanced learners",
      "enforcement": "get_hint tool automatically adjusts based on score"
    },
    {
      "rule_id": "BR006",
      "category": "Productive Failure",
      "rule": "For complex concepts with sandbox: trigger sandbox BEFORE teaching, do NOT help learner succeed",
      "rationale": "Failure creates mental 'slot' for new knowledge",
      "enforcement": "System prompt forbids helping during sandbox"
    },
    {
      "rule_id": "BR007",
      "category": "Anti-Sycophancy",
      "rule": "NEVER validate learner claims without verification: 'I get it' must trigger diagnostic question",
      "rationale": "Prevents illusion of understanding",
      "enforcement": "System prompt: 'ALWAYS verify, NEVER trust blindly'"
    },
    {
      "rule_id": "BR008",
      "category": "FSRS Scheduling",
      "rule": "Review intervals determined by FSRS-5 algorithm: stability, difficulty, rating (1-4)",
      "rationale": "Optimizes retention vs study time",
      "enforcement": "FSRS library calculates intervals, stored in next_review_date"
    },
    {
      "rule_id": "BR009",
      "category": "Review Priority",
      "rule": "Review priority: relearning > learning > review > new",
      "rationale": "Concepts in danger of being forgotten are most important",
      "enforcement": "SQL ORDER BY in get_due_reviews"
    },
    {
      "rule_id": "BR010",
      "category": "Session Notes",
      "rule": "end_session session_notes must include: what was worked on, blockers, learner state, next steps, meta-learning observations",
      "rationale": "Ensures seamless continuity across sessions",
      "enforcement": "Tool description provides detailed guidelines"
    },
    {
      "rule_id": "BR011",
      "category": "Emotional Detection",
      "rule": "infer_emotional_state should be called every ~20 minutes OR when frustration signals detected",
      "rationale": "Prevents learner burnout",
      "enforcement": "System prompt specifies timing"
    },
    {
      "rule_id": "BR012",
      "category": "Exit Ticket",
      "rule": "If concepts_introduced.length > 0: exit ticket is required, must pass before ending session",
      "rationale": "Verifies retention before learner leaves",
      "enforcement": "get_exit_ticket checks concepts_introduced, returns skip=false if any"
    },
    {
      "rule_id": "BR013",
      "category": "Code Snippets",
      "rule": "Code snippets for SRS must be ~500 chars max, include context (project + function name)",
      "rationale": "Keeps token cost low, provides context for reviews",
      "enforcement": "store_code_snippet tool truncates, requires snippet_context"
    },
    {
      "rule_id": "BR014",
      "category": "Milestone Advancement",
      "rule": "Cannot advance milestone without verification pass",
      "rationale": "Prevents proceeding with misunderstandings",
      "enforcement": "System prompt requires verification before advance_milestone"
    },
    {
      "rule_id": "BR015",
      "category": "Learning Preferences",
      "rule": "When AI detects learning pattern (e.g., physical analogy worked), must call update_learning_preferences",
      "rationale": "Adapts teaching to learner's style",
      "enforcement": "System prompt specifies detection triggers"
    },
    {
      "rule_id": "BR016",
      "category": "Question Prompting",
      "rule": "If 0 questions in session after 30 min: call should_prompt_questions, prompt learner",
      "rationale": "Combats passive learning",
      "enforcement": "System prompt specifies timing"
    },
    {
      "rule_id": "BR017",
      "category": "Onboarding",
      "rule": "Learner must complete onboarding before accessing projects",
      "rationale": "Ensures track selection and setup completion",
      "enforcement": "get_project_state returns onboarding_incomplete if not done"
    },
    {
      "rule_id": "BR018",
      "category": "Active Project",
      "rule": "Only one project can have status='in_progress' per learner",
      "rationale": "Focus on one project at a time",
      "enforcement": "Database queries filter WHERE status='in_progress'"
    },
    {
      "rule_id": "BR019",
      "category": "Prerequisites",
      "rule": "Concepts with prerequisites can only be introduced after prerequisites are introduced",
      "rationale": "Ensures learning scaffolding",
      "enforcement": "concept.prerequisites array checked before introduction"
    },
    {
      "rule_id": "BR020",
      "category": "Time Tracking",
      "rule": "AI never gives time estimates or predictions for task duration",
      "rationale": "Prevents false expectations",
      "enforcement": "System prompt: 'Never give time estimates... Focus on what needs to be done, not how long'"
    }
  ],

  "workflows": [
    {
      "workflow_id": "WF001",
      "name": "New Learner Onboarding",
      "steps": [
        "User opens Avaia app",
        "Preflight check runs (Claude CLI, MCP config, database, API key)",
        "If setup incomplete: redirect to /setup",
        "Setup wizard installs dependencies",
        "User sets API key (login OR BYOK)",
        "Preflight cache invalidated",
        "User creates learner profile",
        "User selects learning track",
        "First project from track is created with status='in_progress'",
        "Onboarding marked complete",
        "User redirected to chat interface"
      ]
    },
    {
      "workflow_id": "WF002",
      "name": "Typical Learning Session",
      "steps": [
        "PHASE 1: Check-in (3-5 min) - AI calls start_session(learner_id), retrieves: learning_preferences, previous session notes, due_reviews, stubborn_bugs, known_terms",
        "AI adapts greeting based on learning_preferences (e.g., physical analogies if flagged)",
        "If reviews due: AI asks ONE quick recall question using code snippet",
        "AI asks: 'How are you feeling today?' (emotional baseline)",
        "PHASE 2: Goal (2-3 min) - AI calls get_next_step() to prioritize: stubborn_bugs > reviews > current_milestone",
        "AI states session goal clearly",
        "PHASE 3: Sandbox (10-15 min, if applicable) - AI calls trigger_sandbox(concept_id), if sandbox exists and not completed, AI presents ill-structured problem, instructs learner to try 2-3 approaches, does NOT help learner succeed, calls evaluate_sandbox_attempt() after attempts, asks reflection questions",
        "PHASE 4: Build (25-35 min) - Learner works on project milestone, when learner asks for help: AI calls get_hint(concept_id, learner_id) for scaffolded hint, every 20 min: AI calls infer_emotional_state() to check frustration/disengagement, if 0 questions: AI calls should_prompt_questions(), prompts learner",
        "PHASE 5: Concept Introduction (when needed) - Learner hits blocker requiring new knowledge, AI calls introduce_concept(learner_id, concept_id, context), AI stores relevant code snippet for SRS, AI explains using learner's actual code, AI connects to sandbox failure if applicable",
        "PHASE 6: Verification (5-10 min, MANDATORY) - AI asks: 'On a scale of 1-5, how confident are you?', AI asks open-ended: 'Explain in your own words', AI calls get_diagnostic_question(learner_id, concept_id), AI generates contextual question using learner's code, AI presents 4 options (1 correct, 3 distractors), If wrong: AI calls verify_concept() with misconception_id, If HIGH confidence + WRONG: AI flags stubborn bug, calls get_contrasting_case(), shows side-by-side code, asks 'What's the ONE difference?'",
        "PHASE 7: Reflection + Exit Ticket (5 min) - AI asks: 'What did we accomplish today?', AI calls get_exit_ticket(session_id), AI presents ONE diagnostic question about today's code, If fail: quick remediation, repeat, AI asks: 'What's next for next session?', AI calls end_session() with complete session notes"
      ]
    },
    {
      "workflow_id": "WF003",
      "name": "Spaced Repetition Review Cycle",
      "steps": [
        "System calculates due reviews: concepts where next_review_date <= now OR state='new'",
        "AI calls get_due_reviews(learner_id, limit=3)",
        "For each review: AI retrieves code snippet from learner's project, AI shows snippet + context (e.g., 'From Task Tracker, handleSubmit function'), AI asks diagnostic question",
        "Learner answers + provides confidence (1-5)",
        "AI calls log_review(learner_id, concept_id, outcome, confidence, response_time_ms)",
        "System calculates rating: outcome + confidence + response_time → FSRS rating (1-4)",
        "FSRS algorithm updates: stability, difficulty, state, reps, lapses",
        "System calculates next_review_date: now + scheduledDays",
        "System updates learner_concept with new FSRS state",
        "System returns: new stability, next review date, days until next review"
      ]
    },
    {
      "workflow_id": "WF004",
      "name": "Stubborn Bug Remediation",
      "steps": [
        "AI detects high confidence (≥4) + wrong answer during verification",
        "AI calls flag_stubborn_bug(learner_id, concept_id, misconception_id)",
        "System adds misconception_id to learner_concept.stubborn_misconceptions array",
        "AI says: 'You were confident, but that's not right. Let's dig into this.'",
        "AI calls get_contrasting_case(misconception_id)",
        "AI shows two code snippets side by side",
        "AI asks: 'What's the ONE difference that changes the outcome?'",
        "Learner explains difference",
        "AI clarifies misconception",
        "AI asks follow-up verification question",
        "Only after pass: AI removes from stubborn_misconceptions, proceeds"
      ]
    },
    {
      "workflow_id": "WF005",
      "name": "Productive Failure Exercise",
      "steps": [
        "AI is about to teach complex concept",
        "AI calls trigger_sandbox(concept_id)",
        "If sandbox exists and learner hasn't completed it: AI presents problem_statement + setup_code, AI says: 'Try at least 2-3 different approaches. Write down what happens.'",
        "AI does NOT help learner succeed",
        "Learner makes attempts (min 2)",
        "AI calls evaluate_sandbox_attempt(sandbox_id, learner_id, code, approach_description, outcome)",
        "System matches outcome to expected_failures array",
        "System records: matched_failure_pattern, articulation_quality (none | partial | complete)",
        "AI asks reflection_questions from sandbox",
        "AI explains why failure occurred",
        "AI uses teaching_transition text to bridge to concept",
        "AI teaches concept with failure as context: 'Remember when your while loop froze? This is why...'",
        "Sandbox marked complete"
      ]
    },
    {
      "workflow_id": "WF006",
      "name": "Emotional Intervention",
      "steps": [
        "AI logs message timing via log_message_timing(session_id, gap_ms, message_type)",
        "After ~20 min OR frustration signals: AI calls infer_emotional_state(session_id, recent_timings)",
        "System analyzes: timing gaps, help request patterns, question count",
        "System infers state: flow | struggling | frustrated | disengaged | passive",
        "System logs state to session.emotional_states",
        "AI calls get_intervention(emotional_state)",
        "AI receives suggested script",
        "If struggling: AI reduces difficulty, offers more scaffolding, checks prerequisites",
        "If frustrated: AI says 'This seems frustrating. Want to take a break or try a different approach?'",
        "If disengaged: AI says 'You seem distracted. Everything okay? We can pause if needed.'",
        "If passive: AI says 'What questions do you have? Even partial ones are valuable.'",
        "If flow: AI continues normally, doesn't interrupt momentum"
      ]
    },
    {
      "workflow_id": "WF007",
      "name": "Learning Preference Detection",
      "steps": [
        "AI explains concept abstractly",
        "Learner is still confused after 2 attempts",
        "AI switches to physical metaphor: 'Let me try a different approach. Imagine you're holding index cards...'",
        "Physical metaphor works (learner understands)",
        "AI calls update_learning_preferences(learner_id, prefers_physical_analogies: true)",
        "System stores preference in learner.learning_preferences JSON",
        "Next session: start_session returns learning_preferences",
        "AI leads with physical analogies BEFORE abstract explanations"
      ]
    },
    {
      "workflow_id": "WF008",
      "name": "Dynamic Curriculum Generation",
      "steps": [
        "Learner says: 'I want to learn [Rust]'",
        "AI calls get_learning_tracks()",
        "AI checks if 'Rust' track exists in pre-seeded tracks",
        "Track does NOT exist",
        "AI asks clarifying questions: experience, context, time commitment",
        "AI suggests: 'I'll design a curriculum for you. This works best with Opus. Want to switch?'",
        "Learner confirms",
        "AI calls generate_learning_track(learner_id, goal='Learn Rust for open source', context='Python background, no low-level')",
        "System generates: track definition, project sequence, milestones, concepts",
        "System saves track to database",
        "AI presents: 'Here's your path: 6 projects starting with Command Line Tool...'",
        "Learner confirms",
        "AI calls complete_onboarding(learner_id, track_id=generated_track_id)",
        "First project starts"
      ]
    },
    {
      "workflow_id": "WF009",
      "name": "Cross-Project Refactoring Challenge",
      "steps": [
        "AI detects concept with low stability (significant decay)",
        "AI calls get_refactoring_challenge(learner_id, concept_id, current_project_id)",
        "System retrieves: cross_project_code (from different project), current_project_code, related_concepts",
        "If cross_project_code exists: AI asks 'You used [concept] in [previous project]. How would you apply it here?'",
        "If only current_project_code: AI asks 'Can you refactor this code to use [concept]?'",
        "If no code: AI generates small focused exercise",
        "Challenge is 5-10 minute task",
        "Learner completes challenge",
        "AI verifies with diagnostic question",
        "Completion updates FSRS state (log_review)"
      ]
    },
    {
      "workflow_id": "WF010",
      "name": "Exit Ticket Administration",
      "steps": [
        "Session ending (learner says 'bye', 'goodnight', etc.)",
        "AI calls get_exit_ticket(session_id)",
        "System retrieves concepts_introduced from session",
        "If concepts_introduced.length === 0: System returns skip=true, AI proceeds to end_session",
        "If concepts introduced: System picks random concept, retrieves diagnostic_question, shuffles options",
        "AI presents exit ticket: 'Before you go, one quick question...'",
        "AI shows code snippet + question + 4 options",
        "Learner answers",
        "If correct: AI calls end_session(exit_ticket_passed=true)",
        "If incorrect: AI provides quick remediation, asks follow-up, only then calls end_session"
      ]
    }
  ],

  "hidden_features": [
    {
      "feature": "Bypass Onboarding (Admin Mode)",
      "description": "Learners can skip onboarding by directly setting onboarding_complete=TRUE in database",
      "detection": "Database query in get_project_state checks onboarding_complete flag",
      "purpose": "Development/testing shortcut"
    },
    {
      "feature": "Direct API Key Storage",
      "description": "API key can be stored at ~/.avaia/api_key as plain text file",
      "detection": "Server reads from file path if exists",
      "purpose": "BYOK (Bring Your Own Key) without Claude.ai login",
      "security_note": "Plain text storage - user responsibility"
    },
    {
      "feature": "Migration System Idempotency",
      "description": "Migrations silently ignore 'duplicate column' and 'already exists' errors",
      "detection": "Migration runner catches these specific error messages",
      "purpose": "Allows re-running migrations without failure"
    },
    {
      "feature": "Debug Logging",
      "description": "Complete debug log at ~/.avaia/debug.log",
      "detection": "Logging configured at startup in server_webview.py",
      "purpose": "Troubleshooting without verbose console output"
    },
    {
      "feature": "Preflight Cache Invalidation",
      "description": "Setting API key invalidates preflight check cache, forcing re-check",
      "detection": "POST /setup/auth/byok calls invalidate_preflight_cache()",
      "purpose": "Ensures setup wizard re-validates after API key change"
    },
    {
      "feature": "Dynamic Port Selection",
      "description": "Flask server finds free port dynamically instead of hardcoded port",
      "detection": "find_free_port() function in server_webview.py",
      "purpose": "Avoids port conflicts when multiple instances run"
    },
    {
      "feature": "Auto-Logging at GUI Level",
      "description": "Chat messages logged to database automatically by Flask server, not AI tool calls",
      "detection": "auto_log_message() function in server_webview.py",
      "purpose": "Zero AI token overhead for logging"
    },
    {
      "feature": "Offline Speech Recognition",
      "description": "Whisper WASM runs entirely in browser via Transformers.js",
      "detection": "Frontend imports @xenova/transformers pipeline",
      "purpose": "Privacy + no API costs for voice input"
    },
    {
      "feature": "System Prompt Caching",
      "description": "System prompt cached after first read, checked by mtime",
      "detection": "_cached_system_prompt and _cached_prompt_mtime in server_webview.py",
      "purpose": "Reduce file I/O on every request"
    },
    {
      "feature": "WAL Mode for SQLite",
      "description": "Database uses Write-Ahead Logging for concurrent reads",
      "detection": "PRAGMA journal_mode=WAL in get_db()",
      "purpose": "Better performance for multi-threaded Flask app"
    },
    {
      "feature": "Session History in LocalStorage",
      "description": "Chat messages stored in browser localStorage for instant reload",
      "detection": "Frontend JavaScript persists messages",
      "purpose": "Session continuity without database query on page refresh"
    },
    {
      "feature": "Model Override",
      "description": "User can select Opus/Haiku instead of default Sonnet",
      "detection": "modelSelect dropdown in sidebar, sent with each message",
      "purpose": "Cost/performance tradeoff control"
    },
    {
      "feature": "Curriculum Update API",
      "description": "App can check for and apply npm package updates + migrations",
      "detection": "GET /api/curriculum/status, POST /api/curriculum/update",
      "purpose": "Distribute curriculum updates without full app rebuild"
    },
    {
      "feature": "Direct Anthropic API (Not Claude CLI)",
      "description": "Desktop app bypasses Claude CLI and calls Anthropic API directly",
      "detection": "anthropic Python SDK imported, API key used directly",
      "purpose": "Faster responses, better WebSocket integration"
    },
    {
      "feature": "Frozen App Bundle Path Handling",
      "description": "PyInstaller frozen app uses sys._MEIPASS for resource paths",
      "detection": "if getattr(sys, 'frozen', False): BASE_DIR = sys._MEIPASS",
      "purpose": "Bundled macOS app finds templates/static files"
    }
  ],

  "negative_constraints": [
    {
      "constraint": "Age Restriction",
      "rule": "No age validation implemented",
      "implication": "Assumes learners are self-directed adults or supervised minors"
    },
    {
      "constraint": "Account Deletion",
      "rule": "No learner deletion endpoint exposed",
      "implication": "Learners cannot self-delete accounts (GDPR consideration)"
    },
    {
      "constraint": "Multi-Learner Households",
      "rule": "No authentication system - relies on learner_id only",
      "implication": "Multiple learners sharing one machine must manually switch IDs"
    },
    {
      "constraint": "Network Errors",
      "rule": "No retry logic for Anthropic API failures",
      "implication": "Network blips interrupt sessions, require user restart"
    },
    {
      "constraint": "Code Execution",
      "rule": "No sandboxed code execution environment",
      "implication": "Learner must run code in their own environment"
    },
    {
      "constraint": "Token Budget",
      "rule": "No per-learner token usage limits",
      "implication": "Uncontrolled API costs if API key is shared/leaked"
    },
    {
      "constraint": "Session Timeout",
      "rule": "No automatic session end after inactivity",
      "implication": "Learners must explicitly end sessions or they remain open indefinitely"
    },
    {
      "constraint": "Concurrent Projects",
      "rule": "Only one project can be 'in_progress' at a time",
      "implication": "Learners cannot work on multiple projects simultaneously"
    },
    {
      "constraint": "Track Switching",
      "rule": "No mechanism to switch tracks after onboarding",
      "implication": "Learners are locked into chosen track (would need database edit)"
    },
    {
      "constraint": "Concept Deletion",
      "rule": "No cascade delete for concepts with dependencies",
      "implication": "Removing curriculum concepts would break referential integrity"
    },
    {
      "constraint": "Migration Rollback",
      "rule": "No down migrations - only forward",
      "implication": "Cannot undo schema changes without manual SQL"
    },
    {
      "constraint": "Offline Mode",
      "rule": "Requires internet for AI (except speech recognition)",
      "implication": "Cannot use teaching features offline"
    },
    {
      "constraint": "Platform Support",
      "rule": "Desktop app is macOS-only (uses pywebview with WebKit)",
      "implication": "Windows/Linux users must use CLI or build custom GUI"
    },
    {
      "constraint": "Diagnostic Question Pool",
      "rule": "If no diagnostic questions exist for concept, AI generates ad-hoc question",
      "implication": "Quality varies - pre-written questions preferred"
    },
    {
      "constraint": "Session Notes Length",
      "rule": "No character limit on session_notes field",
      "implication": "AI could write excessive summaries (unlikely but possible)"
    }
  ],

  "api_endpoints": [
    {
      "endpoint": "GET /",
      "description": "Main chat interface",
      "authentication": "None (requires setup complete)"
    },
    {
      "endpoint": "GET /setup",
      "description": "Setup wizard UI"
    },
    {
      "endpoint": "GET /setup/status",
      "description": "Returns preflight check status (Claude CLI, MCP, DB, API key)"
    },
    {
      "endpoint": "POST /setup/install/<component>",
      "description": "Installs component: claude-cli, mcp-config, database",
      "parameters": "component: str"
    },
    {
      "endpoint": "POST /setup/auth/login",
      "description": "Initiates Claude.ai login flow"
    },
    {
      "endpoint": "POST /setup/auth/byok",
      "description": "Sets Anthropic API key (Bring Your Own Key)",
      "parameters": "api_key: str"
    },
    {
      "endpoint": "GET /dashboard",
      "description": "Learner metrics dashboard UI"
    },
    {
      "endpoint": "GET /api/dashboard",
      "description": "Dashboard data (sessions, concepts, streak)",
      "parameters": "learner_id: str",
      "returns": "JSON: total_sessions, total_time, streak, concepts_mastered, concepts_learning, due_reviews, stubborn_bugs, current_project, track_progress"
    },
    {
      "endpoint": "GET /learning",
      "description": "Concepts & vocabulary view UI"
    },
    {
      "endpoint": "GET /api/learning",
      "description": "Mastered/learning concepts + vocabulary",
      "parameters": "learner_id: str",
      "returns": "JSON: mastered_concepts, learning_concepts, known_terms"
    },
    {
      "endpoint": "GET /projects",
      "description": "Project progress tracker UI"
    },
    {
      "endpoint": "GET /api/projects",
      "description": "Track progress, project list",
      "parameters": "learner_id: str",
      "returns": "JSON: track_info, projects (status, milestones, time_spent)"
    },
    {
      "endpoint": "GET /reviews",
      "description": "SRS review queue UI"
    },
    {
      "endpoint": "GET /api/reviews",
      "description": "Due reviews with diagnostic questions",
      "parameters": "learner_id: str",
      "returns": "JSON: reviews array with code_snippet, question, options"
    },
    {
      "endpoint": "POST /api/log-review",
      "description": "Log review result, update FSRS",
      "parameters": "learner_id: str, concept_id: str, outcome: str, confidence: int, response_time_ms: int"
    },
    {
      "endpoint": "GET /api/learner/exists",
      "description": "Check if learner exists",
      "parameters": "learner_id: str",
      "returns": "JSON: exists: bool"
    },
    {
      "endpoint": "POST /api/learner/create",
      "description": "Create new learner",
      "parameters": "name: str (optional), preferred_teaching_method: str",
      "returns": "JSON: learner_id: str"
    },
    {
      "endpoint": "GET /api/learner/profile",
      "description": "Get learner info",
      "parameters": "learner_id: str",
      "returns": "JSON: name, started_at, preferred_teaching_method, best_session_times, onboarding_complete"
    },
    {
      "endpoint": "GET /api/tracks",
      "description": "Available learning tracks",
      "returns": "JSON: tracks array"
    },
    {
      "endpoint": "POST /api/select-track",
      "description": "Assign track to learner",
      "parameters": "learner_id: str, track_id: str"
    },
    {
      "endpoint": "POST /api/set-api-key",
      "description": "Set Anthropic API key",
      "parameters": "api_key: str"
    },
    {
      "endpoint": "GET /api/curriculum/status",
      "description": "Check for npm + migration updates",
      "returns": "JSON: npm_update_available: bool, pending_migrations: int"
    },
    {
      "endpoint": "POST /api/curriculum/update",
      "description": "Apply pending updates (npm + migrations)"
    }
  ],

  "websocket_events": [
    {
      "event": "input",
      "direction": "Client → Server",
      "payload": "learner_id: str, model: str, message: str",
      "description": "Send message to AI, initiates streaming response"
    },
    {
      "event": "stop",
      "direction": "Client → Server",
      "description": "Terminate current AI response"
    },
    {
      "event": "restart",
      "direction": "Client → Server",
      "description": "Reset conversation (new session)"
    },
    {
      "event": "end_session",
      "direction": "Client → Server",
      "description": "End current learning session"
    },
    {
      "event": "status",
      "direction": "Server → Client",
      "payload": "message: str",
      "description": "Connection status updates"
    },
    {
      "event": "output",
      "direction": "Server → Client",
      "payload": "chunk: str",
      "description": "Streaming AI response chunks"
    },
    {
      "event": "tool_use",
      "direction": "Server → Client",
      "payload": "tool_name: str, tool_args: dict",
      "description": "Tool being invoked by AI"
    },
    {
      "event": "tool_result",
      "direction": "Server → Client",
      "payload": "tool_name: str, result: dict",
      "description": "Tool result returned"
    },
    {
      "event": "response_complete",
      "direction": "Server → Client",
      "description": "AI finished responding"
    },
    {
      "event": "stopped",
      "direction": "Server → Client",
      "description": "Process terminated by user"
    },
    {
      "event": "error",
      "direction": "Server → Client",
      "payload": "error: str",
      "description": "Error occurred"
    }
  ],

  "mcp_tools": [
    {
      "tool": "start_session",
      "category": "Session Management",
      "description": "Initialize session with consolidated check-in data",
      "parameters": "learner_id: str, project_id?: str, planned_duration_minutes?: int",
      "returns": "session_id, learner_name, learning_preferences, track_progress, previous_session (notes), project_state, due_reviews, stubborn_bugs, known_terms"
    },
    {
      "tool": "end_session",
      "category": "Session Management",
      "description": "End session, save natural language notes",
      "parameters": "session_id: str, learner_id: str, session_notes: str (MANDATORY), exit_ticket_passed?: bool",
      "returns": "duration_minutes, concepts_introduced_count, concepts_verified_count, milestones_completed_count"
    },
    {
      "tool": "get_current_time",
      "category": "Utility",
      "description": "AI never guesses time - always calls this",
      "returns": "iso: str, unix_ms: int, formatted: str"
    },
    {
      "tool": "infer_emotional_state",
      "category": "Emotional Intelligence",
      "description": "Detect frustration/disengagement from timing patterns",
      "parameters": "session_id: str, recent_timings: array",
      "returns": "state (flow|struggling|frustrated|disengaged|passive), confidence: float, suggested_action: str, intervention: str"
    },
    {
      "tool": "log_message_timing",
      "category": "Emotional Intelligence",
      "description": "Record timing metadata for emotion inference",
      "parameters": "session_id: str, timestamp: str, gap_ms: int, message_type: enum, message_length?: int, contains_help_request?: bool"
    },
    {
      "tool": "get_intervention",
      "category": "Emotional Intelligence",
      "description": "Get intervention script for emotional state",
      "parameters": "emotional_state: enum",
      "returns": "suggested_script: str"
    },
    {
      "tool": "log_emotional_checkin",
      "category": "Emotional Intelligence",
      "description": "Record explicit emotional check-in",
      "parameters": "session_id: str, learner_response: str, inferred_state?: enum"
    },
    {
      "tool": "get_exit_ticket",
      "category": "Session Management",
      "description": "Get end-of-session diagnostic question",
      "parameters": "session_id: str",
      "returns": "skip: bool, concept_id: str, question: object (code_snippet, prompt, options, correct_answer)"
    },
    {
      "tool": "get_session_summary",
      "category": "Session Management",
      "description": "Retrieve complete session details",
      "parameters": "session_id: str",
      "returns": "learner, project, duration, concepts, emotional_journey, questions_asked, exit_ticket_passed, session_notes"
    },
    {
      "tool": "get_project_state",
      "category": "Project Management",
      "description": "Get current project, milestone, blockers",
      "parameters": "learner_id: str",
      "returns": "status, project_id, project_name, current_milestone, milestones_completed, time_spent_minutes"
    },
    {
      "tool": "advance_milestone",
      "category": "Project Management",
      "description": "Mark milestone complete, advance to next",
      "parameters": "learner_id: str, project_id: str, milestone_id: int"
    },
    {
      "tool": "get_next_step",
      "category": "Project Management",
      "description": "Determine priority action (stubborn bugs > reviews > build)",
      "parameters": "learner_id: str",
      "returns": "priority: enum, action: enum, details: object"
    },
    {
      "tool": "create_learner",
      "category": "Learner Management",
      "description": "Create new learner profile",
      "parameters": "name?: str, preferred_teaching_method?: enum",
      "returns": "learner_id: str"
    },
    {
      "tool": "get_learner_profile",
      "category": "Learner Management",
      "description": "Get learner info",
      "parameters": "learner_id: str",
      "returns": "name, started_at, preferred_teaching_method, best_session_times, onboarding_complete"
    },
    {
      "tool": "complete_onboarding",
      "category": "Learner Management",
      "description": "Finish setup, start first project",
      "parameters": "learner_id: str, track_id?: str, preferred_teaching_method?: enum, best_session_times?: array",
      "returns": "track_id, first_project_id, first_project_name"
    },
    {
      "tool": "start_project",
      "category": "Project Management",
      "description": "Begin new project",
      "parameters": "learner_id: str, project_name: str",
      "returns": "project_id: str"
    },
    {
      "tool": "update_learning_preferences",
      "category": "Adaptive Teaching",
      "description": "Update learner style preferences (auto-detected)",
      "parameters": "learner_id: str, prefers_physical_analogies?: bool, prefers_direct_feedback?: bool, struggles_with_abstract_execution?: bool, needs_emotional_context?: bool, tangent_prone?: bool, prefers_visual_diagrams?: bool",
      "returns": "learning_preferences: object"
    },
    {
      "tool": "get_due_reviews",
      "category": "Spaced Repetition",
      "description": "Fetch concepts due for review (FSRS)",
      "parameters": "learner_id: str, limit?: int (default 1, max 5)",
      "returns": "reviews: array (concept_id, concept_name, snippet_context, code_snippet, stability)"
    },
    {
      "tool": "log_review",
      "category": "Spaced Repetition",
      "description": "Update FSRS state after review",
      "parameters": "learner_id: str, concept_id: str, outcome: enum, confidence: int (1-5), response_time_ms: int",
      "returns": "new_stability: float, next_review_date: str, message: str"
    },
    {
      "tool": "get_refactoring_challenge",
      "category": "Spaced Repetition",
      "description": "Cross-project exercise for decayed concept",
      "parameters": "learner_id: str, concept_id: str, current_project_id: str",
      "returns": "concept_name, cross_project_code, current_project_code, related_concepts, generation_instructions"
    },
    {
      "tool": "introduce_concept",
      "category": "Concept Learning",
      "description": "MANDATORY when teaching any concept - tracks what learner knows",
      "parameters": "learner_id: str, concept_id: str, context: str, code_snippet?: str",
      "returns": "confirmation"
    },
    {
      "tool": "get_diagnostic_question",
      "category": "Verification",
      "description": "Generate verification question with misconceptions",
      "parameters": "learner_id: str, concept_id: str",
      "returns": "question_id, code_snippet, prompt, options (4), correct_answer, distractors_mapped_to_misconceptions"
    },
    {
      "tool": "verify_concept",
      "category": "Verification",
      "description": "Mark concept verified, detect stubborn bugs",
      "parameters": "learner_id: str, concept_id: str, is_correct: bool, confidence: int, misconception_id?: str",
      "returns": "verified: bool, stubborn_bug_flagged?: bool"
    },
    {
      "tool": "trigger_sandbox",
      "category": "Productive Failure",
      "description": "Check if productive failure exercise required",
      "parameters": "concept_id: str",
      "returns": "sandbox_exists: bool, problem_statement: str, setup_code: str, expected_failures: array, min_attempts: int, reflection_questions: array"
    },
    {
      "tool": "evaluate_sandbox_attempt",
      "category": "Productive Failure",
      "description": "Score sandbox attempt, match failure patterns",
      "parameters": "sandbox_id: str, learner_id: str, code_submitted: str, approach_description: str, outcome: str",
      "returns": "matched_failure_pattern: str, articulation_quality: enum, ready_for_teaching: bool"
    },
    {
      "tool": "should_prompt_questions",
      "category": "Passive Learner Detection",
      "description": "Check if learner has been too passive",
      "parameters": "learner_id: str",
      "returns": "should_prompt: bool, sessions_without_questions: int, prompt_text?: str"
    },
    {
      "tool": "log_learner_question",
      "category": "Question Tracking",
      "description": "Record learner question for engagement tracking",
      "parameters": "session_id: str, learner_id: str, question_text: str, question_type: enum, prompted: bool",
      "returns": "logged: bool, is_why_question: bool"
    },
    {
      "tool": "get_question_patterns",
      "category": "Question Tracking",
      "description": "Analyze learner questioning behavior",
      "parameters": "learner_id: str",
      "returns": "total_questions, avg_per_session, sessions_without_questions, question_types, concern: bool, analysis: str"
    },
    {
      "tool": "log_chat_message",
      "category": "History",
      "description": "Log message for debugging/analysis",
      "parameters": "session_id: str, role: enum, content: str, tool_calls?: array, tool_results?: array, tokens_used?: int"
    },
    {
      "tool": "get_chat_history",
      "category": "History",
      "description": "Retrieve conversation history",
      "parameters": "session_id: str, limit?: int, role_filter?: enum, since_timestamp?: str",
      "returns": "messages: array"
    }
  ],

  "technical_details": {
    "database": {
      "type": "SQLite",
      "path": "~/.avaia/avaia.db",
      "optimizations": [
        "WAL mode (Write-Ahead Logging) for concurrent reads",
        "64MB cache size for query performance",
        "PRAGMA synchronous=NORMAL for speed",
        "Indexes on: learner_concept review dates, session learner+time, concept instances, message timing"
      ],
      "migrations": "Tracked in _migrations table, applied in order (001-008+)"
    },
    "fsrs_algorithm": {
      "version": "FSRS-5",
      "parameters": [
        "stability (memory stability)",
        "difficulty (intrinsic difficulty)",
        "scheduled_days (interval)",
        "elapsed_days (time since last review)",
        "reps (repetition count)",
        "lapses (failure count)",
        "state (new | learning | review | relearning)"
      ],
      "rating_conversion": "outcome + confidence + response_time → rating (1-4)",
      "intervals": "Exponential growth based on stability"
    },
    "pedagogical_techniques": [
      "Productive Failure (deliberate struggle before teaching)",
      "Spaced Repetition (FSRS-5 optimal intervals)",
      "Socratic Method (questions, not answers)",
      "Scaffolded Hints (adaptive to independence)",
      "Contrasting Cases (minimal difference examples)",
      "Token-Efficient SRS (500-char snippets from learner's code)",
      "Anti-Sycophancy (never validate without verification)",
      "Emotional Intelligence (timing-based state inference)",
      "Stubborn Bug Detection (high confidence + wrong → flag)",
      "Just-In-Time Teaching (concepts introduced when needed)",
      "Exit Tickets (session-end verification)",
      "Passive Learner Detection (sessions without questions)"
    ],
    "architecture": {
      "mcp_server": "TypeScript, Node.js, @modelcontextprotocol/sdk",
      "desktop_gui": "Python 3.14, Flask, Flask-SocketIO, pywebview (macOS WebKit)",
      "frontend": "Vanilla JavaScript, Socket.IO client, marked.js, highlight.js, DOMPurify",
      "ai_integration": "Desktop app uses Anthropic Python SDK directly (bypasses Claude CLI for speed)",
      "speech": "Offline Whisper WASM via Transformers.js, Web Speech API for TTS",
      "deployment": "Native macOS app via py2app, MCP server via npm (@newdara/avaia)"
    }
  },

  "quality_attributes": {
    "performance": [
      "Streaming responses via WebSocket (low perceived latency)",
      "System prompt cached after first read",
      "SQLite WAL mode for concurrent reads",
      "Auto-logging at GUI level (zero AI token overhead)",
      "Token-efficient SRS (~500 char snippets, not full files)"
    ],
    "reliability": [
      "Session continuity via session_notes",
      "Preflight checks before app start",
      "Migration system with idempotency",
      "Debug logging to ~/.avaia/debug.log"
    ],
    "usability": [
      "Welcome screen with suggestion cards",
      "Native macOS app (no browser required)",
      "Voice input (offline)",
      "Text-to-speech",
      "Real-time markdown rendering",
      "Sidebar navigation (Dashboard, Learning, Projects, Reviews)",
      "Learner ID persistence"
    ],
    "security": [
      "DOMPurify for XSS protection",
      "API key stored in file (user responsibility for permissions)",
      "No user authentication (single-user desktop app)",
      "CORS allowed origins: * (local app context)"
    ],
    "maintainability": [
      "TypeScript with Zod validation",
      "Modular tool registration",
      "Database migrations system",
      "Comprehensive system prompt documentation",
      "Debug logging"
    ]
  }
}
